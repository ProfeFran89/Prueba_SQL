{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Prueba: SQL**\n",
    "## Francisca Gálvez Lynch - G56\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte 1**: Registro de los archivos en la base de datos. (3 Puntos)\n",
    "- Generar una nueva base de datos con la siguiente nomenclatura: apellido_nombre.\n",
    "- Importar en tablas los archivos train_cupid.csv y test_cupid.csv a un motor Postgres, implementando solo la librería *psycopg2*. Las tablas deben contener los nombres de las columnas y el total de los registros presente en cada archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos conectamos a la base de datos galvez_francisca creada en PostgreSQL\n",
    "conexion = psycopg2.connect(\"dbname=galvez_francisca user=postgres password=123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el cursor con el objeto conexion\n",
    "cur = conexion.cursor();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos DATA TRAIN\n",
    "cur.execute(\"\"\"CREATE TABLE train_cupid(age INT, height FLOAT, virgo INT, taurus INT, scorpio INT, pisces INT, libra INT, leo INT, gemini INT, aries INT, aquarius INT, cancer INT, sagittarius INT, asian INT, hispanic_latin INT, black INT, indian INT, pacific_islander INT, native_american INT, middle_eastern INT, colorado INT, new_york INT, oregon INT, arizona INT, hawaii INT, montana INT, wisconsin INT, virginia INT, spain INT, nevada INT, illinois INT, vietnam INT, ireland INT, louisiana INT, michigan INT, texas INT, united_kingdom INT, massachusetts INT, north_carolina INT, idaho INT, mississippi INT, new_jersey INT, florida INT, minnesota INT, georgia INT, utah INT, washington INT, west_virginia INT, connecticut INT, tennessee INT, rhode_island INT, district_of_columbia INT, canada INT, missouri INT, germany INT, pennsylvania INT, netherlands INT, switzerland INT, mexico INT, ohio INT, agnosticism INT, atheism INT, catholicism INT, buddhism INT, judaism INT, hinduism INT, islam INT, pro_dogs FLOAT, pro_cats FLOAT, spanish INT, chinese INT, french INT, german INT, single INT, seeing_someone INT, available INT, employed INT, income_between_25_50 INT,\tincome_between_50_75 INT, income_over_75 INT, drugs_often INT, drugs_sometimes INT, drinks_not_at_all INT, drinks_often\tINT, drinks_rarely INT, drinks_socially\tINT, drinks_very_often INT, orientation_gay INT, orientation_straight INT, sex_m INT, smokes_sometimes INT, smokes_trying_to_quit INT, smokes_when_drinking INT, smokes_yes INT, body_type_overweight INT, body_type_regular INT, education_high_school INT, education_undergrad_university INT);\"\"\")\n",
    "\n",
    "# Confirmar\n",
    "conexion.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos DATA TEST\n",
    "cur.execute(\"\"\"CREATE TABLE test_cupid(age INT, height FLOAT, virgo INT, taurus INT, scorpio INT, pisces INT, libra INT, leo INT, gemini INT, aries INT, aquarius INT, cancer INT, sagittarius INT, asian INT, hispanic_latin INT, black INT, indian INT, pacific_islander INT, native_american INT, middle_eastern INT, colorado INT, new_york INT, oregon INT, arizona INT, hawaii INT, montana INT, wisconsin INT, virginia INT, spain INT, nevada INT, illinois INT, vietnam INT, ireland INT, louisiana INT, michigan INT, texas INT, united_kingdom INT, massachusetts INT, north_carolina INT, idaho INT, mississippi INT, new_jersey INT, florida INT, minnesota INT, georgia INT, utah INT, washington INT, west_virginia INT, connecticut INT, tennessee INT, rhode_island INT, district_of_columbia INT, canada INT, missouri INT, germany INT, pennsylvania INT, netherlands INT, switzerland INT, mexico INT, ohio INT, agnosticism INT, atheism INT, catholicism INT, buddhism INT, judaism INT, hinduism INT, islam INT, pro_dogs FLOAT, pro_cats FLOAT, spanish INT, chinese INT, french INT, german INT, single INT, seeing_someone INT, available INT, employed INT, income_between_25_50 INT,\tincome_between_50_75 INT, income_over_75 INT, drugs_often INT, drugs_sometimes INT, drinks_not_at_all INT, drinks_often\tINT, drinks_rarely INT, drinks_socially\tINT, drinks_very_often INT, orientation_gay INT, orientation_straight INT, sex_m INT, smokes_sometimes INT, smokes_trying_to_quit INT, smokes_when_drinking INT, smokes_yes INT, body_type_overweight INT, body_type_regular INT, education_high_school INT, education_undergrad_university INT);\"\"\")\n",
    "conexion.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llevar los datos a la BDD DATA TRAIN\n",
    "with open('train_cupid.csv','r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "\n",
    "    for row in reader:\n",
    "        cur.execute(\"INSERT INTO train_cupid VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\", row)\n",
    "        conexion.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llevar los datos a la BDD DATA TEST\n",
    "with open('test_cupid.csv','r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "\n",
    "    for row in reader:\n",
    "        cur.execute(\"INSERT INTO test_cupid VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\", row)\n",
    "        conexion.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte 2**: Entrenamiento de modelos (3.5 Puntos)\n",
    "- Ingestar la tabla de training mediante psycopg2 para el posterior entrenamiento del modelo.\n",
    "- Entrenar los siguientes modelos (sin necesidad de ajustar por hiper parámetros):\n",
    "    - GradientBoostingClassifier, AdaBoostClassifer, RandomForestClassifier, SVC, DecisionTreeClassifier, LogisticRegression, BernoulliNB.\n",
    "- Existen tres vectores objetivos a evaluar: single, seeing someone y available.\n",
    "- Serializar el objeto y preservarlo por cada combinación de modelo entrenado y vector objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modelos\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta desde Postgres\n",
    "cur.execute(\"SELECT * FROM train_cupid\")\n",
    "result = cur.fetchall()\n",
    "\n",
    "# Dataframe\n",
    "df_train = pd.DataFrame(list(result))\n",
    "df_train.columns = ['age', 'height', 'virgo', 'taurus', 'scorpio', 'pisces', 'libra', 'leo', 'gemini', 'aries', 'aquarius', 'cancer', 'sagittarius', 'asian', 'hispanic_latin', 'black', 'indian', 'pacific_islander', 'native_american', 'middle_eastern', 'colorado', 'new_york', 'oregon', 'arizona', 'hawaii', 'montana', 'wisconsin', 'virginia', 'spain', 'nevada', 'illinois', 'vietnam', 'ireland', 'louisiana', 'michigan', 'texas', 'united_kingdom', 'massachusetts', 'north_carolina', 'idaho', 'mississippi', 'new_jersey', 'florida', 'minnesota', 'georgia', 'utah', 'washington', 'west_virginia', 'connecticut', 'tennessee', 'rhode_island', 'district_of_columbia', 'canada', 'missouri', 'germany', 'pennsylvania', 'netherlands', 'switzerland', 'mexico', 'ohio', 'agnosticism', 'atheism', 'catholicism', 'buddhism', 'judaism', 'hinduism', 'islam', 'pro_dogs', 'pro_cats', 'spanish', 'chinese', 'french', 'german', 'single', 'seeing_someone', 'available', 'employed', 'income_between_25_50', 'income_between_50_75', 'income_over_75', 'drugs_often', 'drugs_sometimes', 'drinks_not_at_all', 'drinks_often', 'drinks_rarely', 'drinks_socially', 'drinks_very_often', 'orientation_gay', 'orientation_straight', 'sex_m', 'smokes_sometimes', 'smokes_trying_to_quit', 'smokes_when_drinking', 'smokes_yes', 'body_type_overweight', 'body_type_regular', 'education_high_school', 'education_undergrad_university']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta desde Postgres\n",
    "cur.execute(\"SELECT * FROM test_cupid\")\n",
    "result = cur.fetchall()\n",
    "\n",
    "# Dataframe\n",
    "df_test = pd.DataFrame(list(result))\n",
    "df_test.columns = ['age', 'height', 'virgo', 'taurus', 'scorpio', 'pisces', 'libra', 'leo', 'gemini', 'aries', 'aquarius', 'cancer', 'sagittarius', 'asian', 'hispanic_latin', 'black', 'indian', 'pacific_islander', 'native_american', 'middle_eastern', 'colorado', 'new_york', 'oregon', 'arizona', 'hawaii', 'montana', 'wisconsin', 'virginia', 'spain', 'nevada', 'illinois', 'vietnam', 'ireland', 'louisiana', 'michigan', 'texas', 'united_kingdom', 'massachusetts', 'north_carolina', 'idaho', 'mississippi', 'new_jersey', 'florida', 'minnesota', 'georgia', 'utah', 'washington', 'west_virginia', 'connecticut', 'tennessee', 'rhode_island', 'district_of_columbia', 'canada', 'missouri', 'germany', 'pennsylvania', 'netherlands', 'switzerland', 'mexico', 'ohio', 'agnosticism', 'atheism', 'catholicism', 'buddhism', 'judaism', 'hinduism', 'islam', 'pro_dogs', 'pro_cats', 'spanish', 'chinese', 'french', 'german', 'single', 'seeing_someone', 'available', 'employed', 'income_between_25_50', 'income_between_50_75', 'income_over_75', 'drugs_often', 'drugs_sometimes', 'drinks_not_at_all', 'drinks_often', 'drinks_rarely', 'drinks_socially', 'drinks_very_often', 'orientation_gay', 'orientation_straight', 'sex_m', 'smokes_sometimes', 'smokes_trying_to_quit', 'smokes_when_drinking', 'smokes_yes', 'body_type_overweight', 'body_type_regular', 'education_high_school', 'education_undergrad_university']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df_train.copy()\n",
    "targets = ['single','seeing_someone','available']\n",
    "\n",
    "# Pop de los targets\n",
    "for col_name in df_train.columns:\n",
    "    if col_name in targets:\n",
    "        df_x.pop(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_test = df_test.copy()\n",
    "targets = ['single','seeing_someone','available']\n",
    "\n",
    "# Pop de los targets\n",
    "for col_name in df_test.columns:\n",
    "    if col_name in targets:\n",
    "        df_x_test.pop(col_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función para generar modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_modelos(x_train, y_train):\n",
    "    # Gradient Boosting Classifier\n",
    "    gbc = GradientBoostingClassifier(random_state=89)\n",
    "    gbc.fit(x_train, y_train)\n",
    "    # Adaboost Classifier\n",
    "    abc = AdaBoostClassifier(random_state=89)\n",
    "    abc.fit(x_train, y_train)\n",
    "    # Random Forest\n",
    "    rfc = RandomForestClassifier(random_state=89)\n",
    "    rfc.fit(x_train, y_train)\n",
    "    # SVC\n",
    "    # svc = SVC(random_state=89)\n",
    "    # svc.fit(x_train, y_train)\n",
    "    # DecisionTree\n",
    "    dtc = DecisionTreeClassifier(random_state=89)\n",
    "    dtc.fit(x_train, y_train)\n",
    "    # Logistic Regretion\n",
    "    lrm = LogisticRegression(random_state=89)\n",
    "    lrm.fit(x_train, y_train)\n",
    "    # Bernoulli\n",
    "    bm = BernoulliNB()\n",
    "    bm.fit(x_train, y_train)\n",
    "\n",
    "    return gbc, abc, rfc, dtc, lrm, bm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos target SINGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ProfeFran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "gbc_single, abc_single, rfc_single, dtc_single, lrm_single, bm_single = fit_modelos(df_x, df_train['single'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_single = {'gbc_single': gbc_single,\n",
    "                 'abc_single':abc_single,\n",
    "                 'rfc_single':rfc_single,\n",
    "                 'dtc_single':dtc_single,\n",
    "                 'lrm_single':lrm_single,\n",
    "                 'bm_single':bm_single}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos target SEEING_SOMEONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ProfeFran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "gbc_someone, abc_someone, rfc_someone, dtc_someone, lrm_someone, bm_someone = fit_modelos(df_x, df_train['seeing_someone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_someone = {'gbc_someone': gbc_someone,\n",
    "                 'abc_someone':abc_someone,\n",
    "                 'rfc_someone':rfc_someone,\n",
    "                 'dtc_someone':dtc_someone,\n",
    "                 'lrm_someone':lrm_someone,\n",
    "                 'bm_someone':bm_someone}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos target AVAILABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ProfeFran/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "gbc_available, abc_available, rfc_available, dtc_available, lrm_available, bm_available = fit_modelos(df_x, df_train['available'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_available = {'gbc_available': gbc_available,\n",
    "                 'abc_available':abc_available,\n",
    "                 'rfc_available':rfc_available,\n",
    "                 'dtc_available':dtc_available,\n",
    "                 'lrmavailable':lrm_available,\n",
    "                 'bm_available':bm_available}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serializar modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "for name, model in models_single.items():\n",
    "    pickle.dump({model}, open(f'pickles/model_{name}.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models_someone.items():\n",
    "    pickle.dump({model}, open(f'pickles/model_{name}.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models_available.items():\n",
    "    pickle.dump({model}, open(f'pickles/model_{name}.sav', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parte 3**: Exportación de predicciones (3.5 Puntos)\n",
    "- Ingestar la tabla de testing mediante psycopg2 para la posterior predicción del modelo.\n",
    "- En base a los objetos serializados, predecir y evaluar cuatro queries específicas:\n",
    "    - Query 1: 'atheism', 'asian', 'employed', 'pro_dogs', 'chinese'.\n",
    "    - Query 2: 'income_over_75', 'french', 'german','orientation_straight', 'new york'.\n",
    "    - Query 3: 'education_undergrad_university', 'body_type_regular', 'pro_dogs','employed'.\n",
    "    - Query 4: 'taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism'.\n",
    "- Cada una de estas queries específicas debe ser registrada en la base de datos.\n",
    "- La base de datos creada debe contener las tablas:\n",
    "    - 2 que representan a training y testing.\n",
    "    - 84 que representan a cada una de las combinaciones entre modelo, vector y query específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_predicciones(modelos, data_test):\n",
    "    df_hat = pd.DataFrame()\n",
    "    for name, modelo in modelos.items():\n",
    "        hat = modelo.predict(data_test)\n",
    "        df_hat[f'{name}_hat'] = hat\n",
    "    \n",
    "    return df_hat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "hats_single = data_predicciones(models_single, df_x_test)\n",
    "hats_someone = data_predicciones(models_someone, df_x_test)\n",
    "hats_available = data_predicciones(models_available, df_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gbc_someone_hat</th>\n",
       "      <th>abc_someone_hat</th>\n",
       "      <th>rfc_someone_hat</th>\n",
       "      <th>dtc_someone_hat</th>\n",
       "      <th>lrm_someone_hat</th>\n",
       "      <th>bm_someone_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19938</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19939</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19940</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19941</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19942</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19943 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gbc_someone_hat  abc_someone_hat  rfc_someone_hat  dtc_someone_hat  \\\n",
       "0                    0                0                0                0   \n",
       "1                    0                0                0                0   \n",
       "2                    0                0                0                0   \n",
       "3                    0                0                0                0   \n",
       "4                    0                0                0                0   \n",
       "...                ...              ...              ...              ...   \n",
       "19938                0                0                0                0   \n",
       "19939                0                0                0                0   \n",
       "19940                0                0                0                0   \n",
       "19941                0                0                0                0   \n",
       "19942                0                0                0                0   \n",
       "\n",
       "       lrm_someone_hat  bm_someone_hat  \n",
       "0                    0               0  \n",
       "1                    0               0  \n",
       "2                    0               0  \n",
       "3                    0               0  \n",
       "4                    0               0  \n",
       "...                ...             ...  \n",
       "19938                0               0  \n",
       "19939                0               0  \n",
       "19940                0               0  \n",
       "19941                0               0  \n",
       "19942                0               0  \n",
       "\n",
       "[19943 rows x 6 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hats_someone"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear tablas de predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutamos HATS\n",
    "cur.execute(\"\"\"CREATE TABLE hats_single(gbc_single_hat INT, abc_single_hat INT, rfc_single_hat INT, dtc_single_hat INT, lrm_single_hat INT, bm_single_hat INT);\"\"\")\n",
    "conexion.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"CREATE TABLE hats_someone(gbc_someone_hat INT, abc_someone_hat INT, rfc_someone_hat INT, dtc_someone_hat INT, lrm_someone_hat INT, bm_someone_hat INT);\"\"\")\n",
    "conexion.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"CREATE TABLE hats_available(gbc_available_hat INT, abc_available_hat INT, rfc_available_hat INT, dtc_available_hat INT, lrm_available_hat INT, bm_available_hat INT);\"\"\")\n",
    "conexion.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertar_bdd(hats, nombre_tabla):\n",
    "    for index, row in hats.iterrows():\n",
    "        lista = []\n",
    "        cadena = ''\n",
    "        for i in row.values:\n",
    "            lista.append(int(i))\n",
    "        for i in range(len(lista)):\n",
    "            cadena = cadena+'%s,'\n",
    "        cadena = cadena[:len(cadena)-1]\n",
    "        cur.execute(f\"INSERT INTO {nombre_tabla} VALUES ({cadena})\", lista)\n",
    "        conexion.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar las predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "insertar_bdd(hats_single, 'hats_single')\n",
    "insertar_bdd(hats_someone, 'hats_someone')\n",
    "insertar_bdd(hats_available, 'hats_available')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1: 'atheism', 'asian', 'employed', 'pro_dogs', 'chinese'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta desde Postgres\n",
    "cur.execute(\"SELECT atheism, asian, employed, pro_dogs, chinese FROM test_cupid\")\n",
    "result = cur.fetchall()\n",
    "\n",
    "# Dataframe\n",
    "df_query1 = pd.DataFrame(list(result))\n",
    "df_query1.columns = ['atheism','asian','employed','pro_dogs','chinese']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregar predicciones por modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertar_query_bdd(df_, df_hats, cadena):\n",
    "    df_query = pd.DataFrame()\n",
    "    \n",
    "    for i in enumerate(df_hats.columns):\n",
    "\n",
    "        attr = ''\n",
    "        for word in df_query1.columns:\n",
    "            if word in ['pro_dogs', 'pro_cats','height']:\n",
    "                attr = attr+word+' FLOAT,'\n",
    "            else:\n",
    "                attr = attr+word+' INT,'\n",
    "\n",
    "        cadena_t = cadena+'_'+i[1]\n",
    "        cadena_temp = \"\"\"CREATE TABLE {}({}{} INT);\"\"\".format(cadena_t, attr, i[1])\n",
    "        df_query = df_.copy()\n",
    "        df_query[i[1]] = df_hats[i[1]]\n",
    "        cur.execute(cadena_temp)\n",
    "        conexion.commit()\n",
    "    \n",
    "        insertar_bdd(df_query, cadena_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "insertar_query_bdd(df_query1, hats_single, 'query1')\n",
    "insertar_query_bdd(df_query1, hats_someone, 'query1')\n",
    "insertar_query_bdd(df_query1, hats_available, 'query1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2: 'income_over_75', 'french', 'german','orientation_straight', 'new york'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta desde Postgres\n",
    "cur.execute(\"SELECT income_over_75, french, german, orientation_straight, new_york FROM test_cupid\")\n",
    "result = cur.fetchall()\n",
    "\n",
    "# Dataframe\n",
    "df_query2 = pd.DataFrame(list(result))\n",
    "df_query2.columns = ['income_over_75','french','german','orientation_straight','new_york']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "insertar_query_bdd(df_query2, hats_single, 'query2')\n",
    "insertar_query_bdd(df_query2, hats_someone, 'query2')\n",
    "insertar_query_bdd(df_query2, hats_available, 'query2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 3: 'education_undergrad_university', 'body_type_regular', 'pro_dogs','employed'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta desde Postgres\n",
    "cur.execute(\"SELECT education_undergrad_university, body_type_regular, pro_dogs, employed FROM test_cupid\")\n",
    "result = cur.fetchall()\n",
    "\n",
    "# Dataframe\n",
    "df_query3 = pd.DataFrame(list(result))\n",
    "df_query3.columns = ['education_undergrad_university','body_type_regular','pro_dogs','employed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "insertar_query_bdd(df_query3, hats_single, 'query3')\n",
    "insertar_query_bdd(df_query3, hats_someone, 'query3')\n",
    "insertar_query_bdd(df_query3, hats_available, 'query3')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 4: 'taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulta desde Postgres\n",
    "cur.execute(\"SELECT taurus, indian, washington, income_between_50_75, hinduism FROM test_cupid\")\n",
    "result = cur.fetchall()\n",
    "\n",
    "# Dataframe\n",
    "df_query4 = pd.DataFrame(list(result))\n",
    "df_query4.columns = ['taurus','indian','washington','income_between_50_75','hinduism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "insertar_query_bdd(df_query4, hats_single, 'query4')\n",
    "insertar_query_bdd(df_query4, hats_someone, 'query4')\n",
    "insertar_query_bdd(df_query4, hats_available, 'query4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
